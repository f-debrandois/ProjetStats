---
title: "Projet d'étude de Statistiques"
author: "Maxime Baba, Alexandre Demarquet, Félix de Brandois, Tristan Gay"
institute : "INSA Toulouse / ENSEEIHT"
date: "`r Sys.Date()`"
output: 
  pdf_document :
    toc : TRUE
    toc_depth : 2
    number_section : TRUE
    fig_caption: yes
header-includes:
   - \usepackage{dsfont}
   - \usepackage{color}
   - \newcommand{\1}{\mathds{1}}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(reticulate)
library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(gridExtra)
library(MASS)
library(leaflet)
library(ggfortify)
library(caret)
```

\listoffigures
\newpage

# Introduction
Le but de ce projet est d'étudier différents polluants mesurés par de nombreux EPCI d'Occitanie.\
Nous disposons du jeu de données suivant : \texttt{Data-projetmodIA-2324.csv}.

```{r, echo=FALSE}
data <- read.csv("Data-projetmodIA-2324.csv")
```

Dans la suite de ce rapport, on utilise les notations suivantes :  

- a  


# Analyse descriptive des données
On commence par interpréter les éléments jeu de données.\
Il est composé de différentes observations de polluants ainsi que la date et le lieu de l'observation.

## Analyse unidiemensionnelle
On s'intéresse dans un premier temps aux variables quantitatives du jeu de données (et en particulier aux émissions de polluants).\
La figure \ref{fig:fig1} présente une visualisation de quelques variables quantitatives brutes.\

```{r,echo=F,eval=T}
data_quant=data[,c("nox_kg","so2_kg","pm10_kg","pm25_kg","co_kg","c6h6_kg","nh3_kg","ges_teqco2","ch4_t","co2_t","n2o_t")]
data_quant=as.data.frame(data_quant)
```

```{r , echo=F,eval=F}
head(data_quant)
```


```{r fig1 ,echo=F,eval=TRUE,fig.cap="\\label{fig:fig1}Boxplot des variables nox_kg,co_kg,so2_kg",fig.height=1.5}
g1=ggplot(data_quant)+geom_boxplot(aes(y = nox_kg))
g2=ggplot(data_quant)+geom_boxplot(aes(y = co_kg))
g3=ggplot(data_quant)+geom_boxplot(aes(y =so2_kg ))
grid.arrange(g1,g2,g3,ncol=3)
```

On observe une très grande variance de certaines données comme co_kg. 
En observant l'histogramme des données quantitatives, on observe une distribution fortement asymétrique.
Ainsi, si l'on souhaite effectuer des analyses sur ces données (comme par exemple une analyse en composante principales), nos résultats seront biaisés par la variance et l'asymétrie des données.
On transforme donc les données, comme présenté à la figure suivante.



```{r fig2,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig2}Histogramme de la variable co_kg en brute, scale et scale(log())",fig.height=1.5}
g1=ggplot(data_quant)+ geom_histogram(aes(x = (co_kg)),bins =20 )
g2=ggplot(data_quant)+ geom_histogram(aes(x = scale(co_kg)),bins =20)
g3=ggplot(data_quant)+ geom_histogram(aes(x = scale(log(co_kg))),bins =20)
grid.arrange(g1,g2,g3,ncol=3)
```



```{r,eval=FALSE,echo=FALSE}
#données brutes
g1= ggplot(data = data) + geom_histogram(aes(x = (nox_kg)))
g2= ggplot(data = data) + geom_histogram(aes(x = (so2_kg)))
g3= ggplot(data = data) + geom_histogram(aes(x = (pm10_kg)))
g4= ggplot(data = data) + geom_histogram(aes(x = (pm25_kg)))
g5= ggplot(data = data) + geom_histogram(aes(x = (co_kg)))
g6= ggplot(data = data) + geom_histogram(aes(x = (c6h6_kg)))
g7= ggplot(data = data) + geom_histogram(aes(x = (ges_teqco2)))
g8= ggplot(data = data) + geom_histogram(aes(x = (ch4_t)))
g9= ggplot(data = data) + geom_histogram(aes(x = (co2_t)))
g10= ggplot(data = data) + geom_histogram(aes(x = (n2o_t)))
g11= ggplot(data = data) + geom_histogram(aes(x = (nh3_kg)))
grid.arrange(g1, g2, g3, g4, g5, g6, g11, g7, g8, g9, g10, ncol = 3)
```

```{r,eval=FALSE,echo=FALSE}
#Avec Scale
g1= ggplot(data = data) + geom_histogram(aes(x = scale(nox_kg)))
g2= ggplot(data = data) + geom_histogram(aes(x = scale(so2_kg)))
g3= ggplot(data = data) + geom_histogram(aes(x = scale(pm10_kg)))
g4= ggplot(data = data) + geom_histogram(aes(x = scale(pm25_kg)))
g5= ggplot(data = data) + geom_histogram(aes(x = scale(co_kg)))
g6= ggplot(data = data) + geom_histogram(aes(x = scale(c6h6_kg)))
g7= ggplot(data = data) + geom_histogram(aes(x = scale(ges_teqco2)))
g8= ggplot(data = data) + geom_histogram(aes(x = scale(ch4_t)))
g9= ggplot(data = data) + geom_histogram(aes(x = scale(co2_t)))
g10= ggplot(data = data) + geom_histogram(aes(x = scale(n2o_t)))
g11= ggplot(data = data) + geom_histogram(aes(x = scale(nh3_kg)))
grid.arrange(g1, g2, g3, g4, g5, g6, g11, g7, g8, g9, g10, ncol = 3)
```

```{r,eval=FALSE,echo=FALSE}
#Avec scale(log)
g1= ggplot(data = data) + geom_histogram(aes(x = scale(log(nox_kg))))
g2= ggplot(data = data) + geom_histogram(aes(x = scale(log(so2_kg))))
g3= ggplot(data = data) + geom_histogram(aes(x = scale(log(pm10_kg))))
g4= ggplot(data = data) + geom_histogram(aes(x = scale(log(pm25_kg))))
g5= ggplot(data = data) + geom_histogram(aes(x = scale(log(co_kg))))
g6= ggplot(data = data) + geom_histogram(aes(x = scale(log(c6h6_kg))))
g7= ggplot(data = data) + geom_histogram(aes(x = scale(log(ges_teqco2))))
g8= ggplot(data = data) + geom_histogram(aes(x = scale(log(ch4_t))))
g9= ggplot(data = data) + geom_histogram(aes(x = scale(log(co2_t))))
g10= ggplot(data = data) + geom_histogram(aes(x = scale(log(n2o_t))))
g11= ggplot(data = data) + geom_histogram(aes(x = scale(log(nh3_kg))))
grid.arrange(g1, g2, g3, g4, g5, g6, g11, g7, g8, g9, g10, ncol = 3)
```


La transformation la plus adaptée est la transformation $\texttt{scale(log())}$ :
Elle de mettre les données à la même échelle et de réduire l'asymétrie des données pour avoir une distribution plus proche d'une loi normale.\
Par la suite, on manipule les variables quantitatives transformées \texttt{scale(log())}. \

```{r,echo=FALSE,eval=TRUE}
data_quant_scaled <- scale(log(data_quant))
data_scaled_df <- as.data.frame(data_quant_scaled)
```



On étudie ensuite la corrélation entre les variables quantitatives.\

```{r fig3,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig3}Corrélation entre les variables",fig.height=3}
mat_cor <- cor(data_scaled_df)
corrplot(mat_cor,method="ellipse")
```

L'analyse de la figure \ref{fig:fig3} nous permet d'identifier rapidement les relations significatives entre nos variables. Les ellipses fortement allongées suggèrent une corrélation plus forte, tandis que les ellipses plus circulaires indiquent une corrélation plus faible. 




## Analyse multidimensionnelle
A partir de notre jeu de données, on va chercher à résumer l'information en un nombre de variables synthétiques plus faible.\
On effectue pour cela deux types d'analyses : 
une analyse en composante principale (ACP) et une analyse en composante multiple (MCA).\


```{r,eval=F,echo=F}
data_quali=data[,c("code_epci","lib_epci","annee_inv","TypeEPCI","nomdepart")]
table(data_quali[,c("nomdepart")])
```

```{r,eval=F,echo=F}
ggplot(data=data_quali)+geom_bar(aes(x = TypeEPCI))
```


### Analyse en Compomantes Principales (ACP) des variables quantitatives
On s'interesse aux variables quantitatives (émissions de polluants).\
On cherche à visualiser les individus dans un espace de dimension réduite. Nous effectuons donc une ACP sur les variables quantitatives.\


```{r, eval=TRUE, echo=FALSE}
df=data_quant_scaled
pca_res <- prcomp(df)
annee=as.factor(data$annee_inv)
type=as.factor(data$TypeEPCI)
```

On affiche dans un premier temps le cercle des corrélations.\

```{r fig4, eval=TRUE, echo=FALSE,fig.cap="\\label{fig:fig4}Cercle des corrélations",fig.height=3}
g1 = fviz_pca_var(pca_res, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Évite le chevauchement des étiquettes
)
g2 = fviz_pca_var(pca_res, col.var = "contrib",
             axes = c(2, 3),
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Évite le chevauchement des étiquettes
)
grid.arrange(g1,g2,ncol=2)
```

Le premier axe est une combinaison linéaire de...
Le deuxième axe est une combinaison linéaire de...


On a également le pourcentage de variance expliquée par chaque axe à la figure \ref{fig:fig5}.\

```{r fig5, eval=TRUE, echo=FALSE, fig.cap="\\label{fig:fig5}Pourcentage de variance expliquée par chaque axe",fig.height=2.5}
fviz_eig(pca_res, addlabels = TRUE, ylim = c(0, 50))
```

On retrouve bien le fait que les deux premiers axes expliquent presque 90% de la variance.\

On visualise les individus dans le plan factoriel des deux premiers axes principaux en fonction de l'année puis du type d'EPCI.\

```{r fig6, eval=TRUE, echo=FALSE,fig.cap="\\label{fig:fig6}ACP des variables quantitatives",fig.height=2}
g1 = fviz_pca_ind(pca_res,
                  col.ind = annee,
                  palette = "jco",
                  addEllipses = TRUE)
g2 = fviz_pca_ind(pca_res,
                  col.ind = type,
                  palette = "jco",
                  addEllipses = TRUE)
grid.arrange(g1,g2,ncol=2)
```

On observe sur la figure \ref{fig:fig6} que ... \




### Réduction de dimension (MCA)

Dans cette partie, on cherche à effectuer une réduction de dimension pour les polluants et du type EPCI.
Nous allons donc utiliser une MCA (Multiple Correspondance Analysis).\
Les polluants sont des variables quantitatvives nous avons donc besoin de discrétiser ces variables.
Nous allons former un nombre fini d'intervals qui formeront les modalités des nouvelles variables qualitatives.\
**Parler des intervalles de discrétisation**\

Nous allons aussi retirer les valeurs aberrantes c'est-à-dire en-dehors des quantiles (voir boxplot) :
En effet, la MCA est sensible aux valeurs extrêmes car elle vise à maximiser la variance des données.
Les outliers, en raison de leur nature inhabituelle, peuvent influencer significativement la variance et ainsi biaiser les résultats de l'analyse.



```{r, eval=TRUE, echo=FALSE}
# Fonction pour retirer les outliers
enlever_donnee_aber <- function(data_frame,columns) {

  # Définir le facteur d'échelle interquartile (IQR)
  iqr_factor <- 1.5

  # Appliquer la règle des quantiles pour chaque colonne
  for (col in columns) {
    # Calculer les quantiles
    q1 <- quantile(data_frame[[col]], 0.15)
    q3 <- quantile(data_frame[[col]], 0.85)
    # Calculer l'IQR
    iqr <- q3 - q1
    # Calculer les limites
    lower_limit <- q1 - iqr_factor * iqr
    upper_limit <- q3 + iqr_factor * iqr
    # Supprimer les outliers
    data_frame <- data_frame[data_frame[[col]] >= lower_limit & data_frame[[col]] <= upper_limit, ]
  }
  return(data_frame)
}
```


Les données quantitatives sont enrichies en incluant la colonne avec la variable qualitative,
puis les données quantitatives sont transformées en données qualitatives
afin de réaliser une Analyse en Composantes Principales (MCA) à l'aide de FactoMineR.


```{r, eval=TRUE, echo=FALSE}
data_mca <- cbind(data_scaled_df,data$TypeEPCI) # Ajout de la colonne avec typeEPCI

# Changement du nom de la nouvelle colonne 
colnames(data_mca)[colnames(data_mca) == "Data$TypeEPCI"] <- "TypeEPCI"
#On enlève les données aberrantes
data_mca = enlever_donnee_aber(data_mca,colnames(data_mca)[-c(12)]) #on enlève juste la colonne des types EPCI car qualitative

prepa_data_mca<-function(breaks,data_mca) {   
  # Breaks ==Choix du nombre d'intervales de découpe des variables quantitatives

  # Conversion des variables catégorielles en facteurs
  labels <- letters[1:breaks]
  for (col in names(data_mca)) {
    if (is.numeric(data_mca[[col]])) {
      data_mca[[paste0(col, "_discret")]] <- cut(data_mca[[col]], breaks = breaks,labels=labels)
    }
  }
  data_mca=data_mca[,c(names(data_mca)[12:length(names(data_mca))])]
  # Conversion des variables catégorielles en facteurs
  data_mca <- as.data.frame(lapply(data_mca, as.factor))
}
data_mca_3=prepa_data_mca(3,data_mca)
data_mca_4=prepa_data_mca(4,data_mca)
data_mca_5=prepa_data_mca(5,data_mca)

```


Ensuite, nous appliquons l'Analyse en Composantes Principales 
à l'aide de la bibliothèque factoMineR, en variant les intervalles de découpage 
des données quantitatives en données qualitatives.


```{r fig7, eval=TRUE, echo=FALSE,fig.cap="\\label{fig:fig7}MCA avec découpage des données en 3, 4 et 5 intervalles",fig.height=3}
# Réalisation de l'Analyse des Correspondances Multiples (MCA)
mca_result_3 <- MCA(data_mca_3, graph = FALSE)
mca_result_4 <- MCA(data_mca_4, graph = FALSE)
mca_result_5 <- MCA(data_mca_5, graph = FALSE)

# Affichage des résultats
g1 = plot(mca_result_3, axes = c(1, 2), choix = "ind",invisible='ind', habillage = "quali",title = "MCA en 3 intervalles")
g2 = plot(mca_result_4, axes = c(1, 2), choix = "ind",invisible='ind', habillage = "quali",title = "MCA en 4 intervalles")
g3 = plot(mca_result_5, axes = c(1, 2), choix = "ind",invisible='ind', habillage = "quali",title = "MCA en 5 intervalles")
grid.arrange(g1,g2,g3,ncol=3)
```


L'analyse des résultats de la MCA révèle une structure significative
lorsque les variables sont regroupées selon un découpage en trois intervalles. 
Dans ce scénario, les variables partageant le même découpage d'intervalles 
présentent un regroupement cohérent, suggérant une association claire entre ces catégories.

Les deux premiers axes principaux de l'Analyse en Composantes Principales (MCA) 
capturent un pourcentage significatif de la variance totale, 
avec des valeurs respectives de 27% et 17%. 
Ces résultats indiquent que ces axes fournissent une représentation robuste 
des relations entre les variables, soulignant des patterns structurés dans les données.

Cependant, lorsqu'on effectue un découpage en un plus grand nombre d'intervalles, 
les pourcentages associés aux axes principaux diminuent, 
suggérant une dispersion accrue des données. 
Cela peut être interprété comme une indication que le découpage en trois intervalles 
offre une simplification pertinente, 
condensant l'information tout en préservant la structure sous-jacente, 
tandis qu'un découpage plus fin pourrait introduire du bruit ou de la complexité excessive.

En résumé, l'analyse suggère que le découpage en trois intervalles 
optimise la représentation des variables, 
offrant une compréhension significative des relations dans les données, 
tandis qu'un découpage plus fin pourrait conduire à une perte de clarté et à une dilution de l'information utile.


# Classification des EPCI

On cherche à classer les EPCI en fonction de leurs émissions de polluants.\
On utilise pour cela différentes méthodes de classification.\

## Clustering

On met en place différents algorithmes de clustering :\


**Blabla sur les méthodes de clustering**\



## Analyse discriminante linéaire
Dans la partie précédente, nous avons effectué plusieurs types de clustering pour regrouper les données. Le clustering regroupe les individus de manière non supervisée. 
Dans cette partie, nous allons essayer de regrouper les différentes EPCI en fonction de critères prédéfinis. 
Dans un premier temps, nous étudierons le dépassement d'émission de méthane de 1000 tonnes par an, puis nous nous intéresserons au type d'EPCI.

```{r,echo=FALSE,eval=TRUE,message=FALSE}
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant

dlog2=dlog[1:11]
dlog2$ch4_aux=data$ch4_t
dlog2$ch4_t=data$ch4_t>1000

data_mel2 <- dlog2[sample(nrow(dlog2)), ]
```

```{r,echo=FALSE,message=FALSE}
taille_train=round(0.7*nrow(data_mel2))
d_train=data_mel2[1:taille_train,]
d_test=data_mel2[taille_train:nrow(data_mel2),]

# On applique la LDA
lda_model <- lda(ch4_t ~ .,data=d_train)

# On colorie les individus en fonction de leur classe
color2 <- dlog2$ch4_t ;
color2[color2=="TRUE"] <- "black";
color2[color2=="FALSE"] <- "red"

# Projeter les individus dans les coordonnées de la LDA
df_lda =data.frame( predict(lda_model,d_train),d_train["ch4_t"])
mp=df_lda[,4]

# Prédiction sur les données de test
predictions2 <- predict(lda_model, newdata = d_test)
conf_mat=confusionMatrix(predictions2$class,as.factor(d_test$ch4_t))
```

```{r,echo=FALSE,eval=FALSE}
# Afficher les résultats de la LDA
print(lda_model)
summary(df_lda)
plot(lda_model,col=color2)
```

On effectue une analyse linéaire discriminante.
Cette méthode consiste à faire une analyse des composantes principales sur les centroïdes des classes, avec la métrique de Mahalanobis.
Cette métrique permet de "sphériser" les données.
La LDA permet également de trouver la combinaisons linéaires des coordonnées permettant de maximiser la variance inter-classe et de minimiser la variance intra-classe.


### Taux d'émission de méthane
Dans notra cas, nous créeons une nouvelle variable binaire, valant 1 si le taux d'émission de méthane dépasse les 1000 tonnes par an, et 0 sinon.
Nous effectuons ensuite une LDA, et nous pouvons visualiser les résultats dans la figure \ref{fig:fig11}.

```{r fig11,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig11}LDA sur le taux de méthane",fig.height=3}
# Afficher les individus dans le graphique
vec=c(rep(1,nrow(d_train)))
ggplot(df_lda,aes(x=mp,y=vec,color=ch4_t)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("y")
```

Premièrement, nous remarquons que la LDA n'a qu'une seule dimension.
C'est parce que sa dimension vaut le nombre de modalités moins un.
Comme nous avons une variable binaire, le résultat de la LDA ne contient donc qu'une dimension.
Deuxièmement, nous remarquons que le taux d'émission de méthane sépare ici plutôt bien les données.
En effet, les individus en dessous du seuil ont une coordonnée assez faible (négative ou proche de 0).
Tandis que ceux dont le taux de méthane est supérieur au seuil ont une coordonnée grande.
  
  
Afin de vérifier la capacité de classification du taux de méthane, nous allons effectuer un prédiction.
La LDA précédente a été faite sur 70% des individus, afin de pouvoir faire une prédiction sur les 30% restants.
Nous obtenons les résultats sur la figure suivante :

```{r fig12,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig12}Prédiction sur le taux de méthane",fig.height=3}
heatmap_data <- as.data.frame(conf_mat$table)

ggplot(heatmap_data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")
```

Nous pouvons voir grâce à cette table que les individus sont plutôt bien prédits.
En effet, on obtient un taux de précision de `r round(as.numeric(conf_mat$overall[1]), digits=3)`.
Ainsi, utiliser le taux de méthane pour classer les individus de façon supervisée semble judicieux, car pratiquement 95% pourcent des individus seraient correctement prédits avec ce procédé.


### Type d'EPCI
Nous reprenons le même procédé, mais ici avec la variable qualitative type d'EPCI.
Cette variable a 4 modalités, nous allons donc avoir une LDA a trois dimensions.
Nous pouvons visualiser le résultat de la LDA dans la figure \ref{fig:fig3}. Nous pouvons afficher le résultat pour les trois dimensions de la LDA, mais nous avons seulement afficher dans les deux premières dimensions dans la figure \ref{fig:fig3}, car c'est l'affichage le plus parlant.



```{r,echo=FALSE,eval=TRUE}
data_mel <- dlog[sample(nrow(dlog)), ]
```

```{r,echo=FALSE, eval=TRUE}
taille_train=round(0.7*nrow(data_mel))
d_train=data_mel[1:taille_train,]
d_test=data_mel[taille_train:nrow(data_mel),]

# On applique la LDA
lda_model <- lda(TypeEPCI ~ .,data=d_train)

# On colorie les individus en fonction de leur classe
color <- dlog$TypeEPCI ;
color[color=="CC"] <- "black";
color[color=="CA"] <- "red";
color[color=="CU"] <- "green";
color[color=="Metropole"] <- "blue"

# Projeter les individus dans les coordonnées de la LDA
df_lda =data.frame( predict(lda_model,d_train),d_train["TypeEPCI"])

# Prédiction sur les données de test
predictions <- predict(lda_model, newdata = d_test)
conf_mat=confusionMatrix(as.factor(d_test$TypeEPCI),predictions$class)
```

```{r,echo=FALSE,eval=FALSE}
# Afficher les résultats de la LDA
print(lda_model)

# Afficher les individus dans le graphique
ggplot(df_lda,aes(x=x.LD1,y=x.LD3,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD3")
ggplot(df_lda,aes(x=x.LD2,y=x.LD3,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD2")+ylab("LD3")
```


```{r fig13,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig13}LDA en fonction des types EPCI",fig.height=3}
ggplot(df_lda,aes(x=x.LD1,y=x.LD2,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")
```


Nous pouvons voir que les données semblent bien séparées, chaque type d'EPCI.
Le type d'EPCI semble bien séparé les données également, et nous allons confirmer ça par quelques prédictions.
Comme pour le taux de méthane, la LDA a été faite sur 70% des données, et nous allons maintenant faire une prédiction sur les 30% restants.  



```{r fig14,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig14}Prédiction sur le type d'EPCI",fig.height=3}
heatmap_data <- as.data.frame(conf_mat$table)

ggplot(heatmap_data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")
```



Nous pouvons voir grâce à la figure \ref{fig:fig14} table que les individus sont plutôt bien prédits.
On obtient un taux de précision de `r round(as.numeric(conf_mat$overall[1]), digits=3)`.
Ainsi, le type d'EPCI différencie bien les individus, et nous obtenons un bon taux de précision.
Cependant, il y a une forte dissimilarité entre les nombres d'individus par modalité.

On essaie alors de regrouper les modalités de type d'EPCI.
On compare les résultats des LDA appliquées sur les regroupements suivants :
- "CU" et "Métropole"
- "CU", "Métropole", et "CA"


```{r,echo=FALSE}
# Regroupement 1
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant
nv_type <- dlog$TypeEPCI
nv_type[nv_type == "CU"] <- "Metr_CU"
nv_type[nv_type == "Metropole"] <- "Metr_CU"
dlog$TypeEPCI <- nv_type

data_mel_1 <- dlog[sample(nrow(dlog)), ]

# Regroupement 2
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant
nv_type <- dlog$TypeEPCI
nv_type[nv_type == "CU"] <- "Metr_CU_CA"
nv_type[nv_type == "Metropole"] <- "Metr_CU_CA"
nv_type[nv_type == "CA"] <- "Metr_CU_CA"
dlog$TypeEPCI <- nv_type

data_mel <- dlog[sample(nrow(dlog)), ]
```

```{r,echo=FALSE, eval=TRUE}
taille_train=round(0.7*nrow(data_mel_1))
d_train_1=data_mel_1[1:taille_train,]
d_test_simp1=data_mel_1[taille_train:nrow(data_mel),]

# On applique la LDA
lda_model_simp1 <- lda(TypeEPCI ~ .,data=d_train_1)

# Projeter les individus dans les coordonnées de la LDA
df_lda_simp1 =data.frame( predict(lda_model_simp1,d_train_1),d_train_1["TypeEPCI"])
```

```{r,echo=FALSE,eval=FALSE}
# Afficher les résultats de la LDA
print(lda_model)
```

```{r,echo=FALSE, eval=TRUE}
taille_train=round(0.7*nrow(data_mel))
d_train=data_mel[1:taille_train,]
d_test_simp2=data_mel[taille_train:nrow(data_mel),]

# On applique la LDA
lda_model_simp2 <- lda(TypeEPCI ~ .,data=d_train)

# Projeter les individus dans les coordonnées de la LDA
df_lda_simp2 =data.frame( predict(lda_model_simp2,d_train),d_train["TypeEPCI"])

# Afficher les individus dans le graphique
vec=c(rep(1,nrow(d_train)))
```

```{r,echo=FALSE,eval=FALSE}
# Afficher les résultats de la LDA
print(lda_model)
```


```{r fig15,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig15}LDA en fonction des types EPCI",fig.height=3}
g1=ggplot(df_lda_simp1,aes(x=x.LD1,y=x.LD2,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")
g2=ggplot(df_lda_simp2,aes(x=LD1,y=vec,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")
grid.arrange(g1,g2,ncol=2)
```

Nous remarquons que nous obtenons maintenant des LDA de dimensions 2 et 1.
Visuellement, nous ne pouvons pas voir si ces regroupements ont été efficaces.
En effet, c'est principalement les classes CA et CC qui sont proches.
Ainsi, lors du premier regroupement, nous observons un résultat très similaire au résultat initial.
Pour le deuxième regroupement, on semble pouvoir observer que les "CC" ont une coordonnée assez faible, contrairement aux "Metr_CU".
Séparer les données à partir de ce regroupement semble plus simple, voyons si les prédictions confirment ceci.


```{r,echo=FALSE}
predictions_simp1 <- predict(lda_model_simp1, newdata = d_test_simp1)
conf_mat_simp1=confusionMatrix(as.factor(d_test_simp1$TypeEPCI),predictions_simp1$class)


predictions_simp2 <- predict(lda_model_simp2, newdata = d_test_simp2)
conf_mat_simp2=confusionMatrix(as.factor(d_test_simp2$TypeEPCI),predictions_simp2$class)
```



```{r fig16,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig16}Prédiction en fonction des types EPCI simplifiés",fig.height=3}
heatmap_data_s1 <- as.data.frame(conf_mat_simp1$table)
heatmap_data_s2 <- as.data.frame(conf_mat_simp2$table)


m1=ggplot(heatmap_data_s1, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

m2=ggplot(heatmap_data_s2, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

grid.arrange(m1,m2,ncol=2)
```

Nous obtenons un taux de précision de `r round(as.numeric(conf_mat_simp1$overall[1]), digits=3)` pour le premier regroupement, et de `r round(as.numeric(conf_mat_simp2$overall[1]), digits=3)` pour le deuxième.
Ainsi, contrairement à ce qu'on a pu penser, nous ne gagnons pas en précision en faisant des regroupements.
Cela vient probablement du fait que les classes "CA" et "CC" sont les plus proches, et donc l'erreur vient principalement d'une erreur de prédiction entre ces deux classes.
Or, nos regroupements n'ont pas agréger ces deux classes, n'améliorant donc pas la précision.


# EMS

## Modèle linéaire

### Modèle d'ANOVA
On explique le gaz à effet de serre en fonction des variables Type et années.\

On utilise un modèle d'ANOVA à deux facteurs avec interaction :
$$
Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \gamma_{ij} + \epsilon_{ij}
$$

**EXPLIQUER LA SIGNIFICATION DES TERMES DU MODELE**\



```{r, eval=TRUE, echo=FALSE}
dlog=data[4:15]
data_quant=scale(log(data[4:14]))
dlog[1:11]=data_quant
dlog=data.frame(dlog,annee_inv=data$annee_inv)

anov2= lm(ges_teqco2 ~TypeEPCI * annee_inv, data=dlog)
summary(anov2)
```

-> Commentaire sur la valeur de R² obtenue.\

On essaie de simplifier le modèle en enlevant les interactions avec un test de sous-modèle :
\begin{align*}
  &\mathcal{H}_0 : \quad Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \epsilon_{ij}\\
  &\mathcal{H}_1 : \quad Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \gamma_{ij} + \epsilon_{ij}
\end{align*}


```{r, eval=TRUE, echo=FALSE}
anov_sans_int=lm(ges_teqco2 ~TypeEPCI + annee_inv, data=dlog)
```

```{r, eval=FALSE, echo=FALSE}
anova(anov_sans_int,anov2)
```


On obtient une p-value de `r round(anova(anov_sans_int,anov2)$Pr[2], digits=3)` > $0.05$.\
On ne rejette pas l'hypothèse de nullité des interactions.\
On garde donc le modèle suivant :
$$
Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \epsilon_{ij}
$$\

On essaie de simplifier le modèle en enlevant les variables non significatives (on fait 2 tests de sous-modèle) :
\begin{align*}
  &\mathcal{H}_0 : \quad Y_{ij} = \mu + \alpha_{i} + \epsilon_{ij}\\
  &\mathcal{H}_1 : \quad Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \epsilon_{ij}\\
  &\\
  &\qquad \qquad \text{ et }\\
  &\\
  &\mathcal{H}_0 : \quad Y_{ij} = \mu + \beta_{j} + \epsilon_{ij}\\
  &\mathcal{H}_1 : \quad Y_{ij} = \mu + \alpha_{i} + \beta_{j} + \epsilon_{ij}
\end{align*}



```{r, eval=TRUE, echo=FALSE}
anov_annee=lm(ges_teqco2 ~annee_inv, data=dlog)
anov_type=lm(ges_teqco2 ~TypeEPCI, data=dlog)
```

```{r, eval=FALSE, echo=FALSE}
anova(anov_annee,anov_sans_int)
anova(anov_type,anov_sans_int)
```


Pour le modèle dépendant uniquement du type d'EPCI, on obtient une p-value de `r round(anova(anov_type,anov_sans_int)$Pr[2], digits=3)` > $0.05$.\
On peut donc enlever l'année dans le modèle :
$$
Y_{ij} = \mu + \alpha_{i} + \epsilon_{ij}
$$

On essaie à nouveau de simplifier le modèle en enlevant les variables non significatives.

```{r, eval=FALSE, echo=FALSE}
anova(lm(ges_teqco2 ~1, data=dlog),anov_type)
```

On obtient cette fois une p-value de `r round(anova(lm(ges_teqco2 ~1, data=dlog),anov_type)$Pr[2], digits=3)` < $0.05$.\
On ne peut donc pas enlever le type d'EPCI dans le modèle.

On vérifie finalement la cohérence du modèle retenu :
```{r, eval=FALSE, echo=FALSE}
anova(anov_type,anov2)
```

On obtient une p-value de `r round(anova(anov_type,anov2)$Pr[2], digits = 3)
` > $0.05$ donc le modèle est cohérent.
On garde donc le modèle :

```{r, eval=FALSE, echo=FALSE}
summary(anov_type)
```



### Régression linéaire

### ANCOVA




## Modèle linéaire généralisé
Nous allons maintenant modéliser le dépassement d'émission de méthane de 1000 tonnes par an en fonction en fonction de l’ammoniac, le protoxyde d’azote, le type d’EPCI et l’année.
On exprime une variable binaire donc le modèle à utiliser est une régression logistique.

$\forall i \in \{1,\dots,n\}$ :
\begin{itemize}
  \item $dep_i$ : variable binaire valant 1 si le taux d'émission de méthane dépasse les 1000 tonnes par an, et 0 sinon.
  \item $nh3kg_i$ : taux d'émission d'ammoniac en kg/hab
  \item $n2ot_i$ : taux d'émission de protoxyde d'azote en kg/hab
  \item $TypeEPCI_i$ : type d'EPCI
  \item $annee_i$ : année
  \item $T = \{CC,CA,CU,Metropole\}$ : ensemble des types d'EPCI
  \item $A = \{2015,2016,2017,2018,2019\}$ : ensemble des années
\end{itemize}

On modélise la probabilité de dépassement de 1000 tonnes par an par le modèle suivant :
$$
\text{(Mod4) : }\begin{cases}
  dep_i \sim \mathcal{B}(\pi_i)\\
   \\
  \pi_i = \theta_0+\theta_1 nh3kg_i + \theta_2 n2ot_i+ \underset{j \in T}{\sum} \beta_j \mathds{1}_{\{TypeEPCI_i = j\}} + \underset{a \in A}{\sum} \alpha_a \mathds{1}_{\{annee_i = a\}}
\end{cases}
$$

```{r,echo=FALSE}
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant
dlog=data.frame(dlog,annee_inv=data$annee_inv)
bon_indice=c(7,9,11,12,13)
dlog=dlog[bon_indice]
dlog$ch4_t=data$ch4_t>1000

#summary(dlog)

mlg_init=glm(ch4_t~.^2,data=dlog,family=binomial(link="logit"))
summary(mlg_init)
```



```{r,echo=FALSE,eval=TRUE}
mlg_sans_interact=glm(ch4_t~.,data=dlog,family=binomial(link="logit"))
anova(mlg_sans_interact,mlg_init,test="Chisq")
```


```{r, echo=FALSE,include=FALSE}
library("MASS")
mlg_bic=stepAIC(mlg_init,trace=F,direction="backward",k=log(nrow(dlog)))
summary(mlg_bic)
```


```{r,echo=FALSE,include=FALSE}
anova(mlg_bic,mlg_init,test="Chisq")
```


Nous avons essayé de simplifier ce modèle, en enlevant les intéractions, mais nous avons rejeté l'hypothèse car nous obtenions un p-valeur trop petite.
Nous avons également essayé de mettre en place une méthode backward pour trouver un sous-modèle acceptable, mais encore une fois nous avons obtenu un p-valeur trop petite, et nous avons rejeté le sous modèle.
Ce modèle ne semble donc pas pouvoir se simplifier, et nous allons tester son efficaité en faisant de la prédiction. 
Nous prenons 70% de l'échantillon pour faire le modèle, et nous testons sur les 30% restants. 


```{r,echo=FALSE}
library(caret)

taille_train=round(0.7*nrow(dlog))
d_train=dlog[1:taille_train,]
d_test=dlog[taille_train:nrow(dlog),]

pred=predict(mlg_init,d_test)
resultat=data.frame(vrai_res=d_test$ch4_t,prediction=pred)
resultat$prediction=resultat$prediction >0.5
resultat$erreur= abs(resultat$prediction-resultat$vrai_res)
taux_erreur=sum(resultat$erreur)/nrow(resultat)
conf_mat=confusionMatrix(as.factor(resultat$prediction),as.factor(resultat$vrai_res))
```


```{r fig20,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig20}Prédiction sur le taux de méthane",fig.height=3}
heatmap_data <- as.data.frame(conf_mat$table)

ggplot(heatmap_data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")
```

Nous obtenons la figure \ref{fig:fig20}.
Ce résultat a un taux de précision de `r round(as.numeric(conf_mat$overall[1]), digits=3)`.
C'est très correct, car avec la LDA nous obtenions un taux de précision de `r round(as.numeric(conf_mat$overall[1]), digits=3)`.
Ainsi, en ne gardant que certaines variables, nous obtenons un score plutôt proche.
On en déduit que l’ammoniac, le protoxyde d’azote, le type d’EPCI et l’année explique bien le dépassement d’émission de méthane de 1000 t par an.



# Conclusion
