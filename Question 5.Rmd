---
title: "Question 5"
date: "2023-12-01"
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
    number_section : TRUE
    fig_caption: yes
---


```{r setup, echo=FALSE, cache=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)

```


```{r,echo=FALSE,message=FALSE}
library(reticulate)
library(ggplot2)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(caret)
library(gridExtra)
library(MASS)

data = read.csv("Data-projetmodIA-2324.csv")
```


```{r,echo=FALSE,eval=TRUE,message=FALSE}
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant
```

## Analyse discriminante linéaire

Nous avons dans la partie précédente effectuer plusieurs types de clustering pour regrouper les données. Le clustering regroupe les individus de manière non supervisée. Dans cette partie, nous allons essayé de regrouper les différentes EPCI en fonction de critères prédéfinis. Dans un premier temps, nous étudierons le dépassement d'émission de méthane de 1000 tonnes par an, puis nous nous intéresserons au type d'EPCI.
  

```{r,echo=FALSE,message=FALSE}
dlog2=dlog[1:11]
dlog2$ch4_aux=data$ch4_t
dlog2$ch4_t=data$ch4_t>1000



data_mel2 <- dlog2[sample(nrow(dlog2)), ]

taille_train=round(0.7*nrow(data_mel2))
d_train=data_mel2[1:taille_train,]
d_test=data_mel2[taille_train:nrow(data_mel2),]

lda_model <- lda(ch4_t ~ .,data=d_train)




color2 <- dlog2$ch4_t ;color2[color2=="TRUE"] <- "black";

color2[color2=="FALSE"] <- "red"



# Afficher les résultats de la LDA
#print(lda_model)


df_lda =data.frame( predict(lda_model,d_train),d_train["ch4_t"])
mp=df_lda[,4]
#summary(df_lda)


#plot(lda_model,col=color2)


predictions2 <- predict(lda_model, newdata = d_test)
conf_mat=confusionMatrix(predictions2$class,as.factor(d_test$ch4_t))



```

  On effectue une analyse linéaire discriminante. Cette méthode consiste à faire une analyse des composantes principales sur les centroïdes des classes, avec la métrique de Mahalanobis. Cette métrique permet de "sphériser" les données. La LDA permet également de trouver la combinaisons linéaires des coordonnées permettant de maximiser la variance inter-classe et de minimiser la variance intra-classe.
  
### Taux d'émission de méthane
  
  Dans notra cas, nous créeons une nouvelle variable binaire, valant 1 si le taux d'émission de méthane dépasse les 1000 tonnes par an, et 0 sinon. Nous effectuons ensuite une LDA, et nous pouvons visualiser les résultats dans la figure \ref{fig:fig1}.

```{r fig1,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig1}LDA sur le taux de méthane",fig.height=3}
# Afficher les individus dans le graphique
vec=c(rep(1,nrow(d_train)))
ggplot(df_lda,aes(x=mp,y=vec,color=ch4_t)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("y")
```
  Premièrement, nous remarquons que la LDA n'a qu'une seule dimension. C'est parce que sa dimension vaut le nombre de modalités moins un. Comme nous avons une variable binaire, le résultat de la LDA ne contient donc qu'une dimension. Deuxièmement, nous remarquons que le taux d'émission de méthane sépare ici plutôt bien les données. En effet, les individus en dessous du seuil ont une coordonnée assez faible (négative ou proche de 0). Tandis que ceux dont le taux de méthane est supérieur au seuil ont une coordonnée grande.
  
  
  Afin de vérifier la capacité de classification du taux de méthane, nous allons effectuer un prédiction. La LDA précédente a été faite sur 70% des individus, afin de pouvoir faire une prédiction sur les 30% restants. Nous obtenons les résultats de la figure \ref{fig:fig2}

```{r fig2,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig2}Prédiction sur le taux de méthane",fig.height=3}
heatmap_data <- as.data.frame(conf_mat$table)

ggplot(heatmap_data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

```
  Nous pouvons voir grâce à cette table que les individus sont plutôt bien prédits. Nous pouvons même afficher le taux de précision de cette prédiction à partir de la matrice de confusion : 
```{r,echo=FALSE,results='asis'} 
cat(as.numeric(conf_mat$overall[1]))
```
.Ainsi, utiliser le taux de méthane pour classer les individus de façon supervisée semble judicieux, car pratiquement 95% pourcent des individus seraient correctement prédits avec ce procédé.


### Type d'EPCI

  Nous reprenons le même procédé, mais ici avec la variable qualitative type d'EPCI. Cette variable a 4 modalités, nous allons donc avoir une LDA a trois dimensions. Nous pouvons visualiser le résultat de la LDA dans la figure \ref{fig:fig3}. Nous pouvons afficher le résultat pour les trois dimensions de la LDA, mais nous avons seulement afficher dans les deux premières dimensions dans la figure \ref{fig:fig3}, car c'est l'affichage le plus parlant.



```{r,echo=FALSE,include=FALSE}


library(factoextra)

data_mel <- dlog[sample(nrow(dlog)), ]


taille_train=round(0.7*nrow(data_mel))
d_train=data_mel[1:taille_train,]
d_test=data_mel[taille_train:nrow(data_mel),]


color <- dlog$TypeEPCI ;color[color=="CC"] <- "black";

color[color=="CA"] <- "red";color[color=="CU"] <- "green"; color[color=="Metropole"] <- "blue"

lda_model <- lda(TypeEPCI ~ .,data=d_train)

# Afficher les résultats de la LDA
#print(lda_model)

# Projeter les individus dans les coordonnées de la LDA
df_lda =data.frame( predict(lda_model,d_train),d_train["TypeEPCI"])

# Afficher les individus dans le graphique


ggplot(df_lda,aes(x=x.LD1,y=x.LD3,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD3")
ggplot(df_lda,aes(x=x.LD2,y=x.LD3,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD2")+ylab("LD3")




```


```{r fig3,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig3}LDA en fonction des types EPCI",fig.height=3}
ggplot(df_lda,aes(x=x.LD1,y=x.LD2,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")

```


  Nous pouvons voir que les données semblent bien séparées, chaque type d'EPCI. Le type d'EPCI semble bien séparé les données également, et nous allons confirmer ça par quelques prédictions. Comme pour le taux de méthane, la LDA a été faite sur 70% des données, et nous allons maintenant faire une prédiction sur les 30% restants.  


```{r,echo=FALSE}

predictions <- predict(lda_model, newdata = d_test)
conf_mat=confusionMatrix(as.factor(d_test$TypeEPCI),predictions$class)
```

```{r fig4,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig4}Prédiction sur le type d'EPCI",fig.height=3}
heatmap_data <- as.data.frame(conf_mat$table)

ggplot(heatmap_data, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

```



 Nous pouvons voir grâce à la figure \ref{fig:fig4} table que les individus sont plutôt bien prédits. Affichons le taux de précision de cette prédiction : 
```{r,echo=FALSE,results='asis'} 
cat(as.numeric(conf_mat$overall[1]))
```
.Ainsi, le type d'EPCI différencie bien les individus, et nous obtenons un bon taux de précision. Cependant, il y a une forte dissimilarité entre les nombres d'individus par modalité. Essayons de regrouper les plus petites modalités entre elles afin de voir ce que nous obtenons. Dans la suite, nous regrouperons donc "CU" et "Métropole"; et nous essayerons aussi de regrouper "CU","Métropole", et "CA".



```{r,echo=FALSE}
dlog=data[4:15]
data_quant=data[4:14]
data_quant=scale(log(data_quant))
dlog[1:11]=data_quant
nv_type <- dlog$TypeEPCI
nv_type[nv_type == "CU"] <- "Metr_CU"
nv_type[nv_type == "Metropole"] <- "Metr_CU"
dlog$TypeEPCI <- nv_type

data_mel_1 <- dlog[sample(nrow(dlog)), ]




taille_train=round(0.7*nrow(data_mel_1))
d_train_1=data_mel_1[1:taille_train,]
d_test_simp1=data_mel_1[taille_train:nrow(data_mel),]

lda_model_simp1 <- lda(TypeEPCI ~ .,data=d_train_1)

# Afficher les résultats de la LDA
#print(lda_model)

# Projeter les individus dans les coordonnées de la LDA
df_lda_simp1 =data.frame( predict(lda_model_simp1,d_train_1),d_train_1["TypeEPCI"])

# Afficher les individus dans le graphique


```

```{r,echo=FALSE}

nv_type <- dlog$TypeEPCI
nv_type[nv_type == "CU"] <- "Metr_CU"
nv_type[nv_type == "Metropole"] <- "Metr_CU"
nv_type[nv_type == "CA"] <- "Metr_CU"

dlog$TypeEPCI <- nv_type

data_mel <- dlog[sample(nrow(dlog)), ]




taille_train=round(0.7*nrow(data_mel))
d_train=data_mel[1:taille_train,]
d_test_simp2=data_mel[taille_train:nrow(data_mel),]

lda_model_simp2 <- lda(TypeEPCI ~ .,data=d_train)

# Afficher les résultats de la LDA
#print(lda_model)

# Projeter les individus dans les coordonnées de la LDA
df_lda_simp2 =data.frame( predict(lda_model_simp2,d_train),d_train["TypeEPCI"])

# Afficher les individus dans le graphique
vec=c(rep(1,nrow(d_train)))


```


```{r fig5,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig3}LDA en fonction des types EPCI",fig.height=3}
g1=ggplot(df_lda_simp1,aes(x=x.LD1,y=x.LD2,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")
g2=ggplot(df_lda_simp2,aes(x=LD1,y=vec,color=TypeEPCI)) + geom_point(size=2)+ ggtitle("LDA Resultats")+xlab("LD1")+ylab("LD2")
grid.arrange(g1,g2,ncol=2)
```

  Nous remarquons que nous obtenons maintenant des LDA de dimensions 2 et 1. Visuellement, nous ne pouvons pas voir si ces regroupements ont été efficaces. En effet, c'est principalement les classes CA et CC qui sont proches. Ainsi, lors du premier regroupement, nous observons un résultat très similaire au résultat initial. Pour le deuxième regroupement, on semble pouvoir observer que les "CC" ont une coordonnée assez faible, contrairement aux "Metr_CU". Séparer les données à partir de ce regroupement semble plus simple, voyons si les prédictions confirment ceci.


```{r,echo=FALSE}
predictions_simp1 <- predict(lda_model_simp1, newdata = d_test_simp1)
conf_mat_simp1=confusionMatrix(as.factor(d_test_simp1$TypeEPCI),predictions_simp1$class)


predictions_simp2 <- predict(lda_model_simp2, newdata = d_test_simp2)
conf_mat_simp2=confusionMatrix(as.factor(d_test_simp2$TypeEPCI),predictions_simp2$class)
```



```{r fig6,echo=FALSE,eval=TRUE,fig.cap="\\label{fig:fig6}Prédiction en fonction des types EPCI simplifiés",fig.height=3}
heatmap_data_s1 <- as.data.frame(conf_mat_simp1$table)
heatmap_data_s2 <- as.data.frame(conf_mat_simp2$table)


m1=ggplot(heatmap_data_s1, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

m2=ggplot(heatmap_data_s2, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  labs(title = "Matrice de Confusion",
       x = "Vraie Valeur",
       y = "Prédiction")

grid.arrange(m1,m2,ncol=2)
```
Nous obtenons un taux de précision de :
```{r,echo=FALSE,results='asis'} 
cat(as.numeric(conf_mat_simp1$overall[1]))
```
 pour le premier regroupement, et de:
```{r,echo=FALSE,results='asis'} 
cat(as.numeric(conf_mat_simp2$overall[1]))
```
pour le deuxième. Ainsi, contrairement à ce qu'on a pu penser, nous ne gagnons pas en précision en faisant des regroupements. Cela vient probablement du fait que les classes "CA" et "CC" sont les plus proches, et donc l'erreur vient principalement d'une erreur de prédiction entre ces deux classes. Or, nos regroupements n'ont pas agréger ces deux classes, n'améliorant donc pas la précision.
